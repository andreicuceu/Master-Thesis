% \Huge

% \todo[inline]{The section names here are just temporary.}
Our first step is to try to understand how much information from the primordial Universe is preserved. We will look at the theoretical limit encountered when trying to reconstruct the final non-linear density field. 

As a field is defined at every point in space, any attempt at representing it with data is inherently imperfect. We would have to measure the density field at every point in the Universe in order to obtain all the information it contains. This fact already implies that no data driven reconstruction will ever succeed at perfectly recovering the primordial density field (unless we manage to make an infinity of measurements).

To show this unavoidable loss of information we performed a `perfect' reconstruction. We call this reconstruction `perfect' because it uses data about the initial positions of all particles (which obviously is not available to observers). However, as we will show in this chapter, not even this perfect reconstruction succeeds at perfectly recovering the primordial matter distribution.

\section{Methods}

% \todo[inline]{Present how we did the perfect reconstruction}

The first step in studying reconstruction is to find a way to test its effectiveness. To do this, we use cosmological N-body simulations. These simulations give us important insights into how structure evolves in the Universe. More importantly for this project, it allows us to compare any reconstructed density field to the real starting density field. We use data from three simulations available to us. The first one is Simulation A presented in~\cite{Pontzen_paired_simulations} (also referred to as Simulation A in this work). The other two simulations are variations of the same initial setup, with smaller size and smaller resolution respectively. The details of all three simulations are presented in Table 1.

\begin{table}[h!]
    \centering
    \begin{tabular}{ |c|c|c|c| } 
        \hline
        Label & Size & Number of Particles & Particle Mass (Solar Masses) \\
        \hline
        Sim A & $(200 Mpc)^3$ & $512^3$ & $6.59 \times 10^9$ \\ 
        \hline
        Sim B & $(200 Mpc)^3$ & $256^3$ & $5.27 \times 10^{10}$ \\ 
        \hline
        Sim C & $(100 Mpc)^3$ & $256^3$ & $6.59 \times 10^9$ \\ 
        \hline
        
    \end{tabular}
    \caption{Details of the three simulations used in this project. They were setup in a way that allows us to study the impact of the resolution (Sim A vs Sim B) and size (sim A vs Sim C)}
    \label{table:1}
\end{table}

The simulations only contain dark matter and the cosmological parameters used were the ones recommended by the WMAP 7-year observations (\cite{2011ApJS..192...18K}). These are no longer our best estimates (\cite{2016A&A...594A..13P}), however for our present purposes they are sufficient as we do not compare to observational data. The simulations were evolved from $z=99$ to $z=0$ using the \textsc{P-Gadget-3} code (\cite{2005MNRAS.364.1105S},~\cite{2008MNRAS.391.1685S}). 

The idea behind a perfect reconstruction is to use data about the initial state of the simulation to perform the reconstruction. We have access to multiple snapshots at various redshifts in our simulations, including the initial positions of all particles (at $z = 99$). Therefore, we used this information to reconstruct the density field. We first measured the density field of various snapshots in the redshift interval $z = 0 - 9$. The field was measured at the particle positions instead of being measured on a regular grid. This is because the density field will be moved along with the particles as described in the next section. After that, the particle positions were replaced with their initial positions taken from the initial snapshot at $z = 99$.


\section{From Images to Statistics}

% \todo[inline]{Show some density slices of the results, and talk about the effects that pop up (e.g. the increase in total mass). Show Power Spectra}

\subsection{The Reconstructed Density Field}

As outlined above, the first step is to measure the density field in a snapshot. Each snapshot contains an indexed list with the positions, velocities and masses of all particles in the simulation. In this chapter, only the positions and masses are needed to perform a perfect reconstruction. To perform the first part of this analysis, we used the \textit{pynbody}\footnote{https://github.com/pynbody/pynbody} package (\cite{2013ascl.soft05002P}). 

\begin{figure}
    \centering
    \includegraphics[width=1\columnwidth]{images/densityFields/densityField.pdf}%
    
    \caption{
    Density slice through Simulation C. The left panel shows the final collapsed density field at redshift 0. The right panel shows the initial smooth density field at redshift 99. The centre panel shows the result of the perfect reconstruction applied to the final field. The collapsed filaments are stretched, but the result is not identical to the initial field. This means there is some information that cannot be recovered.
    }
    
    \label{im:1}
\end{figure}

To have a visual understanding of the reconstruction, we first make some images of the density field. We use \textit{pynbody} to import the initial snapshot and the snapshot at $z=0$. The density field at the particle locations in the final snapshot is calculated and assigned as the density field of the initial snapshot. Density slices through this reconstructed field are compared to the initial and final fields in Figure~\ref{im:1}. 

We can already see from this comparison that the reconstruction has not recovered all the information, as it is not identical to the initial filed. However, the reconstruction spreads out the matter from the collapsed filaments onto a more uniform field. This is exactly the opposite of small initial perturbations collapsing into the filaments. In a way we are trying to run gravity in reverse. Also notice the large difference in the values of the density field. The reconstructed field has density values about 3 orders of magnitude larger than the initial field.

% \todo{also talk about the density distribution}

This large difference is an interesting side effect of our method. At late times, most particles tend to be clumped together. Therefore, when measuring the density field at the particle positions, we will mostly get very high values. These values do not change when moving the particles, so the final field will also have very high values, but this time distributed on an almost uniform grid. This results in an apparent increase in the total mass of the simulation. As this increase is just a result of the way we represent the density field, it needs to be accounted for when analysing the results. To conserve the mass of the simulation, we just divide the density field by the ratio of the total final mass to the total initial mass.

\subsection{Correlation with the Initial Field}

In order to get a better understanding of how well this reconstruction worked, we turn to statistics. A good way to represent the reconstruction is to look at the normalized Cross-Spectrum between the initial and the reconstructed field: $$ \frac{P_{IX}(k)}{\sqrt{P_I(k) * P_X(k)}} $$ where $I$ represents the initial field, and $X$ the reconstructed field. The power spectrum is defined as the Fourier transform of the correlation function of the two fields:
\begin{equation}
    P(k) = \int{d^3y e^{i\textbf{k} \cdot \textbf{y}} \xi(y)}
\end{equation} 
and the correlation function of two overdensity fields is given by:
\begin{equation}
    \xi(|\textbf{x}-\textbf{y}|) = \langle \delta_A(\textbf{x})\delta_B(\textbf{y}) \rangle
\end{equation}

We used the \textsc{GenPK} code\footnote{https://github.com/sbird/GenPK.git} (\cite{2017ascl.soft06006B}) to measure auto and cross power-spectra of \textsc{Gadget} outputs. In order to analyse reconstructed fields, we also modified \textsc{GenPK} to read the fields generated by \textit{pynbody}. However, before calculating the power spectrum, we first calculate the logarithm of the density field. This is an extra step in our reconstruction which has the purpose of reducing the density contrast of the reconstructed field. The initial field has a Gaussian distribution of overdensities. As structure evolves, this distribution becomes skewed towards large scales. It also develops a large positive tail as more and more massive halos are created. However, the negative tail of the function is physically limited by zero density. Therefore, we take the logarithm of this function in an attempt to Gaussianize this distribution and bring it closer to the initial one. We will always perform this step in all our reconstructions.

The original normalized cross-spectra between the initial and the final fields (from Sim A) can be seen in Figure~\ref{fig:3.1}. For small wavenumbers $k$ (corresponding to large scales), the correlation is very good (converges to 1: perfect correlation). On the other hand, for large wavenumbers (corresponding to small scales), the two fields are completely decorrelated. 

\begin{figure}
    \centering
    \includegraphics[width=1\columnwidth]{images/perfRecon/orig.png}%
    
    \caption{
    Normalized cross-spectra between the initial and final density fields as a function of scale. At small wavenumbers $k$ (large scales) the two fields are perfectly correlated because the Universe is not affected by gravitational collapse over such scales (they are both uniform). On the other hand, at large $k$ (small scales) they are decorrelated because the initial field is very uniform, while the final field is very non-uniform on such scales (it contains large empty voids, and small and massive halos). The decorrelation scale moves to smaller $k$ as time goes on due to the progressive collapse of larger and larger overdensities.
    }
    
    \label{fig:3.1}
\end{figure}

The small $k$ convergence towards perfect correlation indicates that information is preserved on these scales. Because of this, both the initial and the final density fields tend to be very uniform, which preserves the correlation. However, over small scales information is lost. The result is a large discrepancy between massive collapsed regions and mostly empty voids. This is in stark contrast to the relative uniformity of the initial field, leading to a breakdown in correlation.

Figure~\ref{fig:3.1} also shows the evolution of this correlation with redshift. The wavenumber at which the two fields decorrelate indicates the progress of gravitational collapse at that redshift. This results in the decorrelation scale moving to smaller wavenumbers with the progress of gravitational collapse. The objective of reconstruction methods is to bring this decorrelation scale to larger $k$ (in order to recover information about the initial field).

The errors in Figure~\ref{fig:3.1} come from the measurement of the power spectrum. As we have a limited size box, when we measure the largest scales, we only have access to very few modes. This leads to a large error. The errors were propagated without taking into account the correlations between the power spectra when calculating the normalization. However, as these are definitely correlated, this is just an upper bound of the error. The large scale convergence towards perfect correlation also indicates that the actual errors are much smaller. As such, we will not be including them in the following plots.

\begin{figure}
    \centering
    \includegraphics[width=1\columnwidth]{images/perfRecon/perfRecon.png}%
    
    \caption{
    Normalized cross-spectra between the initial and the reconstructed fields compared to the original correlation. A large improvement in the correlation was achieved with the perfect reconstruction. This shows up as a shift of the decorrelation scale towards larger $k$ (smaller scales). However, the perfect reconstruction does not lead to a perfect correlation due to the limiting resolution of our density field measurements. When comparing the reconstruction applied to fields at different redshift, we see a trend towards less information at lower redshift. This shows the progress of information loss between $z=9$ and $z=0$.
    }
    
    \label{fig:3.2}
\end{figure}

\section{Analysis}

The results of the perfect reconstruction can be seen in Figure~\ref{fig:3.2}, where we compare it with the original correlation at different redshifts. The cross-spectra presented show a large improvement in the correlation with the initial field. There is also an increase in the amount of information recovered for lower redshifts. This means redshift does not play a role as large in the perfect reconstruction as it originally did. 

\begin{figure}
    \centering
    \includegraphics[width=1\columnwidth]{images/perfRecon/simComp.png}%
    
    \caption{
    Normalized cross-spectra across the three simulations. The left plot shows the original correlation between the initial and the final fields, and the right panel shows the correlation with the reconstructed field. For the original correlations, the size of the simulation plays an important role, with the smaller simulation decorrelating on smaller scales. However, after the reconstruction, the size of the simulation does not seem to have any impact (with Sim A being almost identical to Sim C). In this case, the resolution of the simulation is the only factor that matters, with the larger resolution simulations showing a better correlation.
    }
    
    \label{fig:3.3}
\end{figure}
However, in order to understand this perfect reconstruction, we need to look at the key role played by the resolution of the simulation. Figure~\ref{fig:3.3} shows a comparison of the cross-spectra across the three simulations. For the original correlations, the size of the simulation plays a larger role than the resolution. Simulation C (smaller size) shows a smaller scale of decorrelation. Simulations A and B (same size) are very close, with a slight edge for Simulation B (lower resolution). 

A completely different structure can be seen once we perform the perfect reconstruction. Simulation A and C (same resolution) show identical reconstructed correlation, while the reconstruction in Simulation B (lower resolution) does not perform as well. This indicates that resolution plays a decisive role in the perfect reconstruction. The other limiting factor is the starting redshift. As we have seen, more and more information is lost as we go to lower redshift. The right panel in Figure~\ref{fig:3.3} shows the lowest scale that can be reconstructed from $z=9$ depending on the resolution of our simulation.

The reconstructions in Figure~\ref{fig:3.2} demonstrate that a perfect correlation cannot be achieved even in the ideal case of existing knowledge of all the starting particle positions. Therefore, we have shown the limits of reconstruction techniques. However, a large improvement in the correlation can be seen, with the decorrelation scale moving to very small scales (of the order $1 Mpc$). This ideal reconstruction using perfect knowledge of the particle positions serves as a theoretical upper limit to reconstruction techniques. The perfect reconstruction, along with the original correlation, will always be present in the next chapter when we look at realistic reconstructions. This can give us a better understanding to how well our techniques work.


